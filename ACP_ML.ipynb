{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnYlLmL3fqlT"
      },
      "source": [
        "## Import Needed Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W-eVuS_fqlU",
        "outputId": "b678488f-6118-4631-b873-3c15af3b7da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1eYFcPxsHvYm8XCFVJouNnxAwdfeOz6GP\n",
            "From (redirected): https://drive.google.com/uc?id=1eYFcPxsHvYm8XCFVJouNnxAwdfeOz6GP&confirm=t&uuid=8fbfeb3e-4177-4cb7-9f48-515a82faac63\n",
            "To: /content/text_representation.csv\n",
            "100%|██████████| 395M/395M [00:02<00:00, 138MB/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import logging\n",
        "import warnings\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pandas import ExcelWriter\n",
        "import ast\n",
        "import gdown\n",
        "\n",
        "# ML Training\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
        "\n",
        "# General settings\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "np.random.seed(11)\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#domain = \"Social_Networking\"\n",
        "#domain = \"Games\"\n",
        "domain = \"Productivity\"\n",
        "\n",
        "if domain == \"Social_Networking\":\n",
        "    gdown.download(f\"https://drive.google.com/uc?id=1lBePyxYUnt07yK196EqmvI6UQub7YTgi\", \"text_representation.csv\", quiet=False)\n",
        "    all_features_url = \"https://drive.usercontent.google.com/uc?id=1w32MbVF9KWLHfYk9dPFtRGqc9sh0Ia4w&export=download\"\n",
        "elif domain == \"Games\":\n",
        "    gdown.download(f\"https://drive.google.com/uc?id=12ct1U1PEZhp0-N68E-_d_F4E3Fh7S20c\", \"text_representation.csv\", quiet=False)\n",
        "    all_features_url = \"https://drive.usercontent.google.com/uc?id=1m7WECvmlxLlwIBVfdHiB7EQ6QR2v2D7O&export=download\"\n",
        "elif domain == \"Productivity\":\n",
        "    gdown.download(f\"https://drive.google.com/uc?id=1eYFcPxsHvYm8XCFVJouNnxAwdfeOz6GP\", \"text_representation.csv\", quiet=False)\n",
        "    all_features_url = \"https://drive.usercontent.google.com/uc?id=18657xYO5IVqC3enmMfCYy_RfgEHkvpNb&export=download\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a5PPTFOfqlV"
      },
      "source": [
        "# Load training & testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yCsHIJBxfqlV"
      },
      "outputs": [],
      "source": [
        "# Read data from csv\n",
        "df_1 = pd.read_csv(\"text_representation.csv\")\n",
        "\n",
        "df_1['tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['tfidf']]\n",
        "df_1['w2v'] = [np.array(ast.literal_eval(x)) for x in df_1['w2v']]\n",
        "df_1['ds_w2v'] = [np.array(ast.literal_eval(x)) for x in df_1['ds_w2v']]\n",
        "df_1['w2v_tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['w2v_tfidf']]\n",
        "df_1['ds_w2v_tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['ds_w2v_tfidf']]\n",
        "df_1['elmo'] = [np.array(ast.literal_eval(x)) for x in df_1['elmo']]\n",
        "df_1['bert'] = [np.array(ast.literal_eval(x)) for x in df_1['bert']]\n",
        "df_1['fine_tuned_bert'] = [np.array(ast.literal_eval(x)) for x in df_1['fine_tuned_bert']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4MIQttfnfqlV"
      },
      "outputs": [],
      "source": [
        "# All Features\n",
        "df_2 = pd.read_csv(all_features_url)\n",
        "df_2.drop(['sentence', 'sentence_clean', 'rating', 'sentiment', 'sentiment_id', 'category', 'category_id'], axis='columns', inplace=True)\n",
        "\n",
        "df = pd.concat([df_1,df_2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E4LQI3BEfqlV"
      },
      "outputs": [],
      "source": [
        "# Re-arrange columns\n",
        "\n",
        "df = df[['sentence', 'sentiment', 'sentiment_id', 'tfidf', 'w2v', 'ds_w2v',\n",
        "       'w2v_tfidf', 'ds_w2v_tfidf', 'elmo', 'bert', 'fine_tuned_bert', 'W-negative_Association',\n",
        "       'W-positive_Association', 'num_generic_pos', 'num_generic_neg',\n",
        "       'num_tfidf_pos', 'num_tfidf_neg','num_PMI_pos', 'num_PMI_neg',\n",
        "       'num_tfidf_pos + synonyms','num_tfidf_neg + synonyms',\n",
        "       'num_PMI_pos + synonyms', 'num_PMI_neg + synonyms',\n",
        "       'num_generic_pos + synonyms', 'num_generic_neg + synonyms',\n",
        "       'num_pos_emojis','num_neg_emojis', 'rating', 'category_id', 'aspect_dependent_sentiment_score']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DroFvCmvfqlV"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCEsSTRNfqlV",
        "outputId": "c0c3d9e1-3f07-4889-8a81-8fb7d3d2d99d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'sentiment', 'sentiment_id', 'tfidf', 'w2v', 'ds_w2v',\n",
              "       'w2v_tfidf', 'ds_w2v_tfidf', 'elmo', 'bert', 'fine_tuned_bert',\n",
              "       'W-negative_Association', 'W-positive_Association', 'num_generic_pos',\n",
              "       'num_generic_neg', 'num_tfidf_pos', 'num_tfidf_neg', 'num_PMI_pos',\n",
              "       'num_PMI_neg', 'num_tfidf_pos + synonyms', 'num_tfidf_neg + synonyms',\n",
              "       'num_PMI_pos + synonyms', 'num_PMI_neg + synonyms',\n",
              "       'num_generic_pos + synonyms', 'num_generic_neg + synonyms',\n",
              "       'num_pos_emojis', 'num_neg_emojis', 'rating', 'category_id',\n",
              "       'aspect_dependent_sentiment_score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# print columns (features) names\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cA-NiFhfqlW",
        "outputId": "3cd5c357-0ba4-4b1e-80f1-cd2ed310180e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['W-negative_Association', 'W-positive_Association', 'num_PMI_pos',\n",
              "       'num_PMI_neg', 'rating', 'category_id',\n",
              "       'aspect_dependent_sentiment_score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# select features for the ablation study\n",
        "\n",
        "df_features_1 = df.iloc[:, 11:13]\n",
        "df_features_2 = df.iloc[:, 17:19]\n",
        "df_features_3 = df.iloc[:, 27:]\n",
        "df_features = pd.concat([df_features_1,df_features_2,df_features_3], axis=1)\n",
        "\n",
        "#df_features = df.iloc[:, 11:]\n",
        "df_features.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IvrM2-KPfqlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "39dc3edf-cad9-40c9-961a-5b78ac33dab5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: 'Results/ACP'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mengine_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         )\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m             self._handles = get_handle(\n\u001b[0m\u001b[1;32m   1247\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'Results/ACP'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# open excel file to export the results to it\n",
        "writer = ExcelWriter(\"Results/ACP/\" + domain + \"_best.xlsx\")\n",
        "\n",
        "\n",
        "classifiers = {\"SVM\": LinearSVC(max_iter=100, random_state=11),\n",
        "              \"MLP\": MLPClassifier(max_iter=100, random_state=11),\n",
        "               \"DT\": DecisionTreeClassifier(random_state=11),\n",
        "               \"GNB\": GaussianNB(),\n",
        "               \"LR\": LogisticRegression(random_state=11),\n",
        "               \"KNN\": KNeighborsClassifier()\n",
        "              }\n",
        "\n",
        "text_representations = [\"tfidf\", \"w2v\", \"ds_w2v\", \"w2v_tfidf\", \"ds_w2v_tfidf\", \"elmo\", \"bert\", \"fine_tuned_bert\"]\n",
        "\n",
        "scoring = ['accuracy']\n",
        "\n",
        "col_names = ['model']\n",
        "for x in text_representations:\n",
        "    col_names.append(x)\n",
        "output_results = []\n",
        "\n",
        "for name, classifier in classifiers.items():\n",
        "\n",
        "    avereged_results = [name]\n",
        "\n",
        "    for text_representation in text_representations:\n",
        "\n",
        "        np.random.seed(11)\n",
        "\n",
        "        print(\"\\ncreate the pipeline for \" + name + \" and \" +  text_representation)\n",
        "\n",
        "        X = np.concatenate((np.array(df[text_representation].tolist()), df_features.values), axis=1)\n",
        "        #X = np.array(df[text_representation].tolist())\n",
        "        Y = df[\"sentiment_id\"]\n",
        "\n",
        "        rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=11)\n",
        "        results = cross_validate(classifier, X, Y, cv=rskf, scoring=scoring)\n",
        "\n",
        "        acc = np.mean(results['test_accuracy']) * 100\n",
        "        print('\\nAccuracy:', acc, '%')\n",
        "        avereged_results.append(acc)\n",
        "    output_results.append(avereged_results)\n",
        "\n",
        "# export classifier's results\n",
        "result_df = pd.DataFrame(output_results, columns=col_names)\n",
        "result_df.to_excel(writer, index=False)\n",
        "\n",
        "writer.save()\n",
        "os.system(\"printf '\\a'\") # or '\\7'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0B8tcnUfqlW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}