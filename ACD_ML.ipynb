{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXr7A8kdDDu3"
      },
      "source": [
        "## Import Needed Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UfxL7esDDu5",
        "outputId": "8e5716f4-a8c8-448c-94bf-2ad697d60510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1lBePyxYUnt07yK196EqmvI6UQub7YTgi\n",
            "From (redirected): https://drive.google.com/uc?id=1lBePyxYUnt07yK196EqmvI6UQub7YTgi&confirm=t&uuid=eb275c77-465c-4c05-84e3-d739ab1d8a6e\n",
            "To: /content/text_representation.csv\n",
            "100%|██████████| 326M/326M [00:04<00:00, 75.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import logging\n",
        "import warnings\n",
        "import os\n",
        "from pandas import ExcelWriter\n",
        "import ast\n",
        "import math\n",
        "import gdown\n",
        "\n",
        "# ML Training\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
        "\n",
        "\n",
        "# General settings\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "np.random.seed(11)\n",
        "nltk.download('wordnet')\n",
        "\n",
        "domain = \"Social_Networking\"\n",
        "#domain = \"Games\"\n",
        "#domain = \"Productivity\"\n",
        "\n",
        "text_representation_url = \"\"\n",
        "all_features_url = \"\"\n",
        "\n",
        "if domain == \"Social_Networking\":\n",
        "    gdown.download(f\"https://drive.google.com/uc?id=1lBePyxYUnt07yK196EqmvI6UQub7YTgi\", \"text_representation.csv\", quiet=False)\n",
        "    all_features_url = \"https://drive.usercontent.google.com/uc?id=1w32MbVF9KWLHfYk9dPFtRGqc9sh0Ia4w&export=download\"\n",
        "elif domain == \"Games\":\n",
        "    gdown.download(f\"https://drive.google.com/uc?id=12ct1U1PEZhp0-N68E-_d_F4E3Fh7S20c\", \"text_representation.csv\", quiet=False)\n",
        "    all_features_url = \"https://drive.usercontent.google.com/uc?id=1m7WECvmlxLlwIBVfdHiB7EQ6QR2v2D7O&export=download\"\n",
        "elif domain == \"Productivity\":\n",
        "    gdown.download(f\"https://drive.google.com/uc?id=1eYFcPxsHvYm8XCFVJouNnxAwdfeOz6GP\", \"text_representation.csv\", quiet=False)\n",
        "    all_features_url = \"https://drive.usercontent.google.com/uc?id=18657xYO5IVqC3enmMfCYy_RfgEHkvpNb&export=download\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_J9Lk03DDu6"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rXzFRoUrDDu6"
      },
      "outputs": [],
      "source": [
        "# Read data from csv\n",
        "\n",
        "df_1 = pd.read_csv(\"text_representation.csv\")\n",
        "\n",
        "df_1['tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['tfidf']]\n",
        "df_1['w2v'] = [np.array(ast.literal_eval(x)) for x in df_1['w2v']]\n",
        "df_1['ds_w2v'] = [np.array(ast.literal_eval(x)) for x in df_1['ds_w2v']]\n",
        "df_1['w2v_tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['w2v_tfidf']]\n",
        "df_1['ds_w2v_tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['ds_w2v_tfidf']]\n",
        "df_1['elmo'] = [np.array(ast.literal_eval(x)) for x in df_1['elmo']]\n",
        "df_1['bert'] = [np.array(ast.literal_eval(x)) for x in df_1['bert']]\n",
        "df_1['fine_tuned_bert'] = [np.array(ast.literal_eval(x)) for x in df_1['fine_tuned_bert']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MulkSfE1DDu7"
      },
      "outputs": [],
      "source": [
        "# All features\n",
        "df_2 = pd.read_csv(all_features_url)\n",
        "df_2.drop(['sentence', 'category', 'category_id'], axis='columns', inplace=True)\n",
        "\n",
        "df = pd.concat([df_1,df_2], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1CuhWH-DDu7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atXGMkjvDDu7",
        "outputId": "db791f24-e39a-4ef8-85eb-8b194f47b71a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'category', 'category_id', 'sentiment', 'sentiment_id',\n",
              "       'category_id_sentiment_id', 'rating', 'tfidf', 'w2v', 'ds_w2v',\n",
              "       'w2v_tfidf', 'ds_w2v_tfidf', 'elmo', 'bert', 'fine_tuned_bert',\n",
              "       'Unnamed: 0', 'sentiment', 'sentiment_id', 'rating', 'sentence_clean',\n",
              "       'W-negative_Association', 'W-positive_Association', 'num_generic_pos',\n",
              "       'num_generic_neg', 'num_generic_pos + synonyms',\n",
              "       'num_generic_neg + synonyms', 'num_tfidf_pos', 'num_tfidf_neg',\n",
              "       'num_tfidf_pos + synonyms', 'num_tfidf_neg + synonyms', 'num_PMI_pos',\n",
              "       'num_PMI_neg', 'num_PMI_pos + synonyms', 'num_PMI_neg + synonyms',\n",
              "       'num_pos_emojis', 'num_neg_emojis', 'aspect_dependent_sentiment_score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# print columns (features) names\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mowNHSuiDDu7"
      },
      "outputs": [],
      "source": [
        "# select features for the ablation study\n",
        "\n",
        "#df_features_1 = df.iloc[:, 16:32]\n",
        "#df_features_2 = df.iloc[:, 40:48]\n",
        "#df_features = pd.concat([df_features_1,df_features_2], axis=1)\n",
        "\n",
        "df_features = df.iloc[:, 16:]\n",
        "df_features.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "HI0uLf59DDu7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# open excel file to export the results to it\n",
        "writer = ExcelWriter(\"Results/ACD/\" + domain + \"_all.xlsx\")\n",
        "\n",
        "classifiers = {\"SVM\": LinearSVC(max_iter=100, random_state=11),\n",
        "               \"MLP\": MLPClassifier(max_iter=100, random_state=11),\n",
        "               \"DT\": DecisionTreeClassifier(random_state=11),\n",
        "               \"GNB\": GaussianNB(),\n",
        "               \"LR\": LogisticRegression(random_state=11),\n",
        "               \"KNN\": KNeighborsClassifier()\n",
        "              }\n",
        "\n",
        "text_representations = [\"tfidf\", \"w2v\", \"ds_w2v\", \"w2v_tfidf\", \"ds_w2v_tfidf\", \"elmo\", \"bert\", \"fine_tuned_bert\"]\n",
        "\n",
        "scoring = ['f1_micro']\n",
        "\n",
        "col_names = ['model']\n",
        "for x in text_representations:\n",
        "    col_names.append(x)\n",
        "output_results = []\n",
        "\n",
        "for name, classifier in classifiers.items():\n",
        "\n",
        "    avereged_results = [name]\n",
        "\n",
        "    for text_representation in text_representations:\n",
        "\n",
        "        np.random.seed(11)\n",
        "\n",
        "        print(\"\\ncreate the pipeline for \" + name + \" and \" +  text_representation)\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('smote', SMOTE()),\n",
        "            ('cls', classifier)\n",
        "        ])\n",
        "\n",
        "\n",
        "        X = np.concatenate((np.array(df[text_representation].tolist()), df_features.values), axis=1)\n",
        "        #X = np.array(df[text_representation].tolist())\n",
        "        Y = df[\"category_id\"]\n",
        "\n",
        "        srkf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=11)\n",
        "        results = cross_validate(pipeline, X, Y, cv=srkf, scoring=scoring)\n",
        "\n",
        "        f1 = np.mean(results['test_f1_micro']) * 100\n",
        "        print('Micro F1-Score:', f1, '%')\n",
        "        avereged_results.append(f1)\n",
        "    output_results.append(avereged_results)\n",
        "\n",
        "\n",
        "# export classifier's results\n",
        "result_df = pd.DataFrame(output_results, columns=col_names)\n",
        "result_df.to_excel(writer, index=False)\n",
        "\n",
        "\n",
        "writer.save()\n",
        "os.system(\"printf '\\a'\") # or '\\7'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAwqrIeYDDu7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}