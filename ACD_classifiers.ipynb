{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "from pandas import ExcelWriter\n",
    "import ast\n",
    "import math\n",
    "\n",
    "# ML Training \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "# hide warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "\n",
    "# General settings\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "np.random.seed(11)\n",
    "nltk.download('wordnet')\n",
    "\n",
    "domain = \"Social_Networking\"\n",
    "#domain = \"Games\"\n",
    "#domain = \"Productivity\"\n",
    "\n",
    "text_representation_url = \"\"\n",
    "all_features_url = \"\"\n",
    "\n",
    "if domain == \"Social_Networking\":\n",
    "    text_representation_url = \"https://drive.google.com/uc?id=1-obCouGNTpXLS0UPbwazeuZMNRQCpO_V&export=download\"\n",
    "    all_features_url = \"https://drive.google.com/uc?id=/1QGRqvdnVUst9BQh3_KetuRcrRxWZZSxR&export=download\"\n",
    "elif domain == \"Games\":\n",
    "    text_representation_url = \"https://drive.google.com/uc?id=1mh6gURnnFJ-KeBRpmF9gHjtGhoQ2D6OI&export=download\"\n",
    "    all_features_url = \"https://drive.google.com/uc?id=15zkGkJe5SXA6jEaxUiUE5OQyOC0A7uHg&export=download\"\n",
    "elif domain == \"Productivity\":\n",
    "    text_representation_url = \"https://drive.google.com/uc?id=1AT7-wtIblIlY6HZYzwyQZy_cQWoh8pvE&export=download\"\n",
    "    all_features_url = \"https://drive.google.com/uc?id=0t2J8cXcII_4VgGzcvFgSPTD0PekqcRC&export=download\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from csv\n",
    "\n",
    "df_1 = pd.read_csv(text_representation_url)\n",
    "\n",
    "df_1['tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['tfidf']]\n",
    "df_1['w2v'] = [np.array(ast.literal_eval(x)) for x in df_1['w2v']]\n",
    "df_1['ds_w2v'] = [np.array(ast.literal_eval(x)) for x in df_1['ds_w2v']]\n",
    "df_1['w2v_tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['w2v_tfidf']]\n",
    "df_1['ds_w2v_tfidf'] = [np.array(ast.literal_eval(x)) for x in df_1['ds_w2v_tfidf']]\n",
    "df_1['elmo'] = [np.array(ast.literal_eval(x)) for x in df_1['elmo']]\n",
    "df_1['bert'] = [np.array(ast.literal_eval(x)) for x in df_1['bert']]\n",
    "df_1['fine_tuned_bert'] = [np.array(ast.literal_eval(x)) for x in df_1['fine_tuned_bert']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features\n",
    "df_2 = pd.read_csv(all_features_url)\n",
    "df_2.drop(['sentence', 'category', 'category_id'], axis='columns', inplace=True)\n",
    "\n",
    "df = pd.concat([df_1,df_2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print columns (features) names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features for the ablation study \n",
    "\n",
    "#df_features_1 = df.iloc[:, 16:32]\n",
    "#df_features_2 = df.iloc[:, 40:48]\n",
    "#df_features = pd.concat([df_features_1,df_features_2], axis=1)\n",
    "\n",
    "df_features = df.iloc[:, 16:]\n",
    "df_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# open excel file to export the results to it\n",
    "writer = ExcelWriter(\"Results/ACD/\" + domain + \"_all.xlsx\")\n",
    "    \n",
    "classifiers = {\"SVM\": LinearSVC(max_iter=100, random_state=11),\n",
    "               \"MLP\": MLPClassifier(max_iter=100, random_state=11),\n",
    "               \"DT\": DecisionTreeClassifier(random_state=11),\n",
    "               \"GNB\": GaussianNB(),\n",
    "               \"LR\": LogisticRegression(random_state=11),\n",
    "               \"KNN\": KNeighborsClassifier()\n",
    "              }\n",
    "\n",
    "text_representations = [\"tfidf\", \"w2v\", \"ds_w2v\", \"w2v_tfidf\", \"ds_w2v_tfidf\", \"elmo\", \"bert\", \"fine_tuned_bert\"]\n",
    "\n",
    "scoring = ['f1_micro']\n",
    "\n",
    "col_names = ['model']\n",
    "for x in text_representations:\n",
    "    col_names.append(x)\n",
    "output_results = []\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "\n",
    "    avereged_results = [name]\n",
    "    \n",
    "    for text_representation in text_representations:\n",
    "        \n",
    "        np.random.seed(11)\n",
    "\n",
    "        print(\"\\ncreate the pipeline for \" + name + \" and \" +  text_representation)\n",
    "                \n",
    "        pipeline = Pipeline([\n",
    "            ('smote', SMOTE()),\n",
    "            ('cls', classifier)\n",
    "        ])\n",
    "    \n",
    "    \n",
    "        X = np.concatenate((np.array(df[text_representation].tolist()), df_features.values), axis=1)\n",
    "        #X = np.array(df[text_representation].tolist())\n",
    "        Y = df[\"category_id\"]\n",
    "        \n",
    "        srkf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=11)\n",
    "        results = cross_validate(pipeline, X, Y, cv=srkf, scoring=scoring) \n",
    "        \n",
    "        f1 = np.mean(results['test_f1_micro']) * 100\n",
    "        print('Micro F1-Score:', f1, '%')\n",
    "        avereged_results.append(f1)\n",
    "    output_results.append(avereged_results)\n",
    "    \n",
    "\n",
    "# export classifier's results\n",
    "result_df = pd.DataFrame(output_results, columns=col_names)\n",
    "result_df.to_excel(writer, index=False)\n",
    "\n",
    "\n",
    "writer.save()\n",
    "os.system(\"printf '\\a'\") # or '\\7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
